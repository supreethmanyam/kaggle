{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import gc\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.drop(['ID_code'], axis=1).copy()\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_data_indices = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "# Credits: https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = sorted(list(np.setdiff1d(train.columns, [\"ID_code\", \"target\"])), key=lambda x:int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = test[~test.index.isin(synthetic_data_indices)].reset_index(drop=True)\n",
    "fake_test = test[test.index.isin(synthetic_data_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 201), (100000, 201))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test.shape, fake_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.concat([train, real_test], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_199"
     ]
    }
   ],
   "source": [
    "engineered_columns = []\n",
    "for col in raw_columns:\n",
    "    sys.stdout.write('\\r{}'.format(col))\n",
    "    sys.stdout.flush()\n",
    "    panel[f\"{col}_count\"] = panel[col].map(panel[col].value_counts())\n",
    "    panel[f\"{col}_count_ratio\"] = panel[col]/panel[f\"{col}_count\"]\n",
    "    panel[f\"{col}_count_mult\"] = panel[col] * panel[f\"{col}_count\"]\n",
    "    panel[f\"{col}_val_count_diff\"] = panel[col].rank(ascending=False, pct=True) - panel[f\"{col}_count\"].rank(ascending=False, pct=True)\n",
    "   \n",
    "    engineered_columns.append(f\"{col}_count\")\n",
    "    engineered_columns.append(f\"{col}_count_ratio\")\n",
    "    engineered_columns.append(f\"{col}_count_mult\")\n",
    "    engineered_columns.append(f\"{col}_val_count_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = panel[panel[\"ID_code\"].astype(str).str.startswith(\"train\")].reset_index(drop=True)\n",
    "x_test = panel[panel[\"ID_code\"].astype(str).str.startswith(\"test\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = pd.concat([x_test, fake_test], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "       'bagging_freq': 5,\n",
    "       'bagging_fraction': 0.8,\n",
    "#         'boost_from_average':'false',\n",
    "       'boost': 'gbdt',\n",
    "       'feature_fraction': 0.35, #0.75, 0.5\n",
    "       'learning_rate': 0.01,\n",
    "#        'max_depth': 6,\n",
    "#        'max_bin': 1023,\n",
    "       'metric':'auc',\n",
    "       'min_data_in_leaf': 255,\n",
    "       'min_sum_hessian_in_leaf': 20.0,\n",
    "       'num_leaves': 3,\n",
    "       'reg_alpha': 0.95,\n",
    "       'reg_lambda': 0.95,\n",
    "       'num_threads': -1,\n",
    "       'tree_learner': 'serial',\n",
    "       'objective': 'binary',\n",
    "       'verbosity': 1\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 100000\n",
    "kfold = 5\n",
    "folds = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test_final))\n",
    "model_objects = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold_0\n",
      "1000\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.799575\tvalid_1's auc: 0.790849\n",
      "[1000]\ttraining's auc: 0.834762\tvalid_1's auc: 0.8268\n",
      "[1500]\ttraining's auc: 0.854291\tvalid_1's auc: 0.845596\n",
      "[2000]\ttraining's auc: 0.86708\tvalid_1's auc: 0.857645\n",
      "[2500]\ttraining's auc: 0.876278\tvalid_1's auc: 0.865884\n",
      "[3000]\ttraining's auc: 0.883607\tvalid_1's auc: 0.87269\n",
      "[3500]\ttraining's auc: 0.889621\tvalid_1's auc: 0.878127\n",
      "[4000]\ttraining's auc: 0.894258\tvalid_1's auc: 0.882574\n",
      "[4500]\ttraining's auc: 0.898474\tvalid_1's auc: 0.886185\n",
      "[5000]\ttraining's auc: 0.901624\tvalid_1's auc: 0.888773\n",
      "[11500]\ttraining's auc: 0.923555\tvalid_1's auc: 0.907027\n",
      "[12000]\ttraining's auc: 0.924473\tvalid_1's auc: 0.907834\n",
      "[12500]\ttraining's auc: 0.925301\tvalid_1's auc: 0.908437\n",
      "[13000]\ttraining's auc: 0.926137\tvalid_1's auc: 0.909061\n",
      "[13500]\ttraining's auc: 0.926932\tvalid_1's auc: 0.909643\n",
      "[14000]\ttraining's auc: 0.927644\tvalid_1's auc: 0.91011\n",
      "[14500]\ttraining's auc: 0.928316\tvalid_1's auc: 0.910548\n",
      "[15000]\ttraining's auc: 0.928981\tvalid_1's auc: 0.911016\n",
      "[15500]\ttraining's auc: 0.929635\tvalid_1's auc: 0.91143\n",
      "[16000]\ttraining's auc: 0.930297\tvalid_1's auc: 0.911849\n",
      "[16500]\ttraining's auc: 0.93088\tvalid_1's auc: 0.912202\n",
      "[17000]\ttraining's auc: 0.931448\tvalid_1's auc: 0.912504\n",
      "[17500]\ttraining's auc: 0.932026\tvalid_1's auc: 0.912828\n",
      "[18000]\ttraining's auc: 0.93262\tvalid_1's auc: 0.913113\n",
      "[18500]\ttraining's auc: 0.933201\tvalid_1's auc: 0.913392\n",
      "[19000]\ttraining's auc: 0.933741\tvalid_1's auc: 0.913561\n",
      "[19500]\ttraining's auc: 0.934278\tvalid_1's auc: 0.913856\n",
      "[20000]\ttraining's auc: 0.934803\tvalid_1's auc: 0.914114\n",
      "[20500]\ttraining's auc: 0.935348\tvalid_1's auc: 0.914292\n",
      "[21000]\ttraining's auc: 0.935851\tvalid_1's auc: 0.914465\n",
      "[21500]\ttraining's auc: 0.936362\tvalid_1's auc: 0.914644\n",
      "[22000]\ttraining's auc: 0.936876\tvalid_1's auc: 0.914775\n",
      "[22500]\ttraining's auc: 0.937363\tvalid_1's auc: 0.91493\n",
      "[23000]\ttraining's auc: 0.937848\tvalid_1's auc: 0.915105\n",
      "[23500]\ttraining's auc: 0.938322\tvalid_1's auc: 0.91525\n",
      "[24000]\ttraining's auc: 0.938789\tvalid_1's auc: 0.915386\n",
      "[24500]\ttraining's auc: 0.939258\tvalid_1's auc: 0.915546\n",
      "[25000]\ttraining's auc: 0.939736\tvalid_1's auc: 0.915643\n",
      "[25500]\ttraining's auc: 0.94019\tvalid_1's auc: 0.915792\n",
      "[26000]\ttraining's auc: 0.940644\tvalid_1's auc: 0.915918\n",
      "[26500]\ttraining's auc: 0.941065\tvalid_1's auc: 0.915979\n",
      "[27000]\ttraining's auc: 0.94151\tvalid_1's auc: 0.916074\n",
      "[27500]\ttraining's auc: 0.941922\tvalid_1's auc: 0.916176\n",
      "[28000]\ttraining's auc: 0.942345\tvalid_1's auc: 0.916257\n",
      "[28500]\ttraining's auc: 0.942762\tvalid_1's auc: 0.91629\n",
      "[29000]\ttraining's auc: 0.943202\tvalid_1's auc: 0.916377\n",
      "[29500]\ttraining's auc: 0.943612\tvalid_1's auc: 0.916474\n",
      "[30000]\ttraining's auc: 0.944039\tvalid_1's auc: 0.916545\n",
      "[30500]\ttraining's auc: 0.944457\tvalid_1's auc: 0.9166\n",
      "[31000]\ttraining's auc: 0.944877\tvalid_1's auc: 0.916632\n",
      "[31500]\ttraining's auc: 0.945296\tvalid_1's auc: 0.916657\n",
      "[32000]\ttraining's auc: 0.945697\tvalid_1's auc: 0.916714\n",
      "[32500]\ttraining's auc: 0.946101\tvalid_1's auc: 0.916775\n",
      "[33000]\ttraining's auc: 0.946482\tvalid_1's auc: 0.91687\n",
      "[33500]\ttraining's auc: 0.946868\tvalid_1's auc: 0.916932\n",
      "[34000]\ttraining's auc: 0.947254\tvalid_1's auc: 0.916985\n",
      "[34500]\ttraining's auc: 0.947642\tvalid_1's auc: 0.91704\n",
      "[35000]\ttraining's auc: 0.94803\tvalid_1's auc: 0.917093\n",
      "[35500]\ttraining's auc: 0.948421\tvalid_1's auc: 0.917108\n",
      "[36000]\ttraining's auc: 0.9488\tvalid_1's auc: 0.917137\n",
      "[36500]\ttraining's auc: 0.949173\tvalid_1's auc: 0.917148\n",
      "[37000]\ttraining's auc: 0.949533\tvalid_1's auc: 0.917168\n",
      "[37500]\ttraining's auc: 0.949896\tvalid_1's auc: 0.917189\n",
      "[38000]\ttraining's auc: 0.950255\tvalid_1's auc: 0.91721\n",
      "[38500]\ttraining's auc: 0.950591\tvalid_1's auc: 0.917243\n",
      "[39000]\ttraining's auc: 0.950941\tvalid_1's auc: 0.917288\n",
      "[39500]\ttraining's auc: 0.951278\tvalid_1's auc: 0.9173\n",
      "[40000]\ttraining's auc: 0.951629\tvalid_1's auc: 0.917279\n",
      "[40500]\ttraining's auc: 0.951975\tvalid_1's auc: 0.917331\n",
      "[41000]\ttraining's auc: 0.952326\tvalid_1's auc: 0.917368\n",
      "[41500]\ttraining's auc: 0.952673\tvalid_1's auc: 0.917361\n",
      "[42000]\ttraining's auc: 0.953009\tvalid_1's auc: 0.917387\n",
      "[42500]\ttraining's auc: 0.953349\tvalid_1's auc: 0.917385\n",
      "[43000]\ttraining's auc: 0.95367\tvalid_1's auc: 0.917412\n",
      "[43500]\ttraining's auc: 0.954006\tvalid_1's auc: 0.917433\n",
      "[44000]\ttraining's auc: 0.954343\tvalid_1's auc: 0.917445\n",
      "[44500]\ttraining's auc: 0.954664\tvalid_1's auc: 0.917471\n",
      "[45000]\ttraining's auc: 0.955001\tvalid_1's auc: 0.917508\n",
      "[45500]\ttraining's auc: 0.955312\tvalid_1's auc: 0.917505\n",
      "[46000]\ttraining's auc: 0.95561\tvalid_1's auc: 0.917544\n",
      "[46500]\ttraining's auc: 0.955924\tvalid_1's auc: 0.917526\n",
      "[47000]\ttraining's auc: 0.956215\tvalid_1's auc: 0.917542\n",
      "[47500]\ttraining's auc: 0.956532\tvalid_1's auc: 0.917556\n",
      "[48000]\ttraining's auc: 0.956845\tvalid_1's auc: 0.91759\n",
      "[48500]\ttraining's auc: 0.957141\tvalid_1's auc: 0.917603\n",
      "[49000]\ttraining's auc: 0.957439\tvalid_1's auc: 0.917619\n",
      "[49500]\ttraining's auc: 0.957748\tvalid_1's auc: 0.917587\n",
      "Early stopping, best iteration is:\n",
      "[48923]\ttraining's auc: 0.957389\tvalid_1's auc: 0.91762\n",
      "Fold_1\n",
      "1000\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.799953\tvalid_1's auc: 0.792415\n",
      "[1000]\ttraining's auc: 0.836489\tvalid_1's auc: 0.828564\n",
      "[1500]\ttraining's auc: 0.855104\tvalid_1's auc: 0.846989\n",
      "[2000]\ttraining's auc: 0.867878\tvalid_1's auc: 0.859233\n",
      "[2500]\ttraining's auc: 0.876831\tvalid_1's auc: 0.867514\n",
      "[3000]\ttraining's auc: 0.884364\tvalid_1's auc: 0.874347\n",
      "[3500]\ttraining's auc: 0.890152\tvalid_1's auc: 0.879629\n",
      "[4000]\ttraining's auc: 0.89483\tvalid_1's auc: 0.883597\n",
      "[4500]\ttraining's auc: 0.898903\tvalid_1's auc: 0.886907\n",
      "[5000]\ttraining's auc: 0.902124\tvalid_1's auc: 0.88953\n",
      "[5500]\ttraining's auc: 0.905003\tvalid_1's auc: 0.891945\n",
      "[6000]\ttraining's auc: 0.907481\tvalid_1's auc: 0.893854\n",
      "[6500]\ttraining's auc: 0.909745\tvalid_1's auc: 0.895653\n",
      "[7000]\ttraining's auc: 0.911836\tvalid_1's auc: 0.89721\n",
      "[7500]\ttraining's auc: 0.913664\tvalid_1's auc: 0.898708\n",
      "[8000]\ttraining's auc: 0.915379\tvalid_1's auc: 0.899849\n",
      "[8500]\ttraining's auc: 0.916882\tvalid_1's auc: 0.90114\n",
      "[9000]\ttraining's auc: 0.918259\tvalid_1's auc: 0.90214\n",
      "[9500]\ttraining's auc: 0.919587\tvalid_1's auc: 0.903063\n",
      "[10000]\ttraining's auc: 0.920811\tvalid_1's auc: 0.903907\n",
      "[10500]\ttraining's auc: 0.921938\tvalid_1's auc: 0.904759\n",
      "[11000]\ttraining's auc: 0.922967\tvalid_1's auc: 0.905384\n",
      "[11500]\ttraining's auc: 0.923962\tvalid_1's auc: 0.906082\n",
      "[12000]\ttraining's auc: 0.924897\tvalid_1's auc: 0.906698\n",
      "[12500]\ttraining's auc: 0.925716\tvalid_1's auc: 0.907347\n",
      "[13000]\ttraining's auc: 0.926512\tvalid_1's auc: 0.907861\n",
      "[13500]\ttraining's auc: 0.927245\tvalid_1's auc: 0.908242\n",
      "[14000]\ttraining's auc: 0.927971\tvalid_1's auc: 0.908685\n",
      "[14500]\ttraining's auc: 0.928699\tvalid_1's auc: 0.909174\n",
      "[15000]\ttraining's auc: 0.929371\tvalid_1's auc: 0.909556\n",
      "[15500]\ttraining's auc: 0.929994\tvalid_1's auc: 0.909961\n",
      "[16000]\ttraining's auc: 0.930631\tvalid_1's auc: 0.910303\n",
      "[16500]\ttraining's auc: 0.931231\tvalid_1's auc: 0.910604\n",
      "[17000]\ttraining's auc: 0.931852\tvalid_1's auc: 0.910913\n",
      "[17500]\ttraining's auc: 0.932441\tvalid_1's auc: 0.911169\n",
      "[18000]\ttraining's auc: 0.933001\tvalid_1's auc: 0.911425\n",
      "[18500]\ttraining's auc: 0.933535\tvalid_1's auc: 0.911728\n",
      "[19000]\ttraining's auc: 0.934065\tvalid_1's auc: 0.91187\n",
      "[19500]\ttraining's auc: 0.934614\tvalid_1's auc: 0.912062\n",
      "[20000]\ttraining's auc: 0.935134\tvalid_1's auc: 0.912287\n",
      "[20500]\ttraining's auc: 0.935638\tvalid_1's auc: 0.912517\n",
      "[21000]\ttraining's auc: 0.936145\tvalid_1's auc: 0.912631\n",
      "[21500]\ttraining's auc: 0.936648\tvalid_1's auc: 0.912755\n",
      "[22000]\ttraining's auc: 0.937163\tvalid_1's auc: 0.912885\n",
      "[22500]\ttraining's auc: 0.937667\tvalid_1's auc: 0.913052\n",
      "[23000]\ttraining's auc: 0.938151\tvalid_1's auc: 0.91319\n",
      "[23500]\ttraining's auc: 0.938594\tvalid_1's auc: 0.913283\n",
      "[24000]\ttraining's auc: 0.93906\tvalid_1's auc: 0.913441\n",
      "[24500]\ttraining's auc: 0.939548\tvalid_1's auc: 0.913577\n",
      "[25000]\ttraining's auc: 0.940021\tvalid_1's auc: 0.913673\n",
      "[25500]\ttraining's auc: 0.940462\tvalid_1's auc: 0.913728\n",
      "[26000]\ttraining's auc: 0.940899\tvalid_1's auc: 0.913805\n",
      "[26500]\ttraining's auc: 0.941352\tvalid_1's auc: 0.913863\n",
      "[27000]\ttraining's auc: 0.941793\tvalid_1's auc: 0.913896\n",
      "[27500]\ttraining's auc: 0.942218\tvalid_1's auc: 0.914\n",
      "[28000]\ttraining's auc: 0.942635\tvalid_1's auc: 0.914039\n",
      "[28500]\ttraining's auc: 0.943085\tvalid_1's auc: 0.914151\n",
      "[29000]\ttraining's auc: 0.943495\tvalid_1's auc: 0.914208\n",
      "[29500]\ttraining's auc: 0.9439\tvalid_1's auc: 0.914276\n",
      "[30000]\ttraining's auc: 0.944326\tvalid_1's auc: 0.914335\n",
      "[30500]\ttraining's auc: 0.944726\tvalid_1's auc: 0.914437\n",
      "[31000]\ttraining's auc: 0.945132\tvalid_1's auc: 0.914455\n",
      "[31500]\ttraining's auc: 0.945526\tvalid_1's auc: 0.914504\n",
      "[32000]\ttraining's auc: 0.945901\tvalid_1's auc: 0.914526\n",
      "[32500]\ttraining's auc: 0.946294\tvalid_1's auc: 0.914579\n",
      "[33000]\ttraining's auc: 0.946684\tvalid_1's auc: 0.914626\n",
      "[33500]\ttraining's auc: 0.947062\tvalid_1's auc: 0.914678\n",
      "[34000]\ttraining's auc: 0.947448\tvalid_1's auc: 0.914704\n",
      "[34500]\ttraining's auc: 0.947828\tvalid_1's auc: 0.914756\n",
      "[35000]\ttraining's auc: 0.948209\tvalid_1's auc: 0.914804\n",
      "[35500]\ttraining's auc: 0.948578\tvalid_1's auc: 0.91484\n",
      "[36000]\ttraining's auc: 0.948935\tvalid_1's auc: 0.914857\n",
      "[36500]\ttraining's auc: 0.949303\tvalid_1's auc: 0.914905\n",
      "[37000]\ttraining's auc: 0.949681\tvalid_1's auc: 0.914927\n",
      "[37500]\ttraining's auc: 0.950048\tvalid_1's auc: 0.914955\n",
      "[38000]\ttraining's auc: 0.950397\tvalid_1's auc: 0.915007\n",
      "[38500]\ttraining's auc: 0.950745\tvalid_1's auc: 0.915012\n",
      "[39000]\ttraining's auc: 0.951105\tvalid_1's auc: 0.915094\n",
      "[39500]\ttraining's auc: 0.951437\tvalid_1's auc: 0.915086\n",
      "[40000]\ttraining's auc: 0.951768\tvalid_1's auc: 0.915081\n",
      "Early stopping, best iteration is:\n",
      "[39071]\ttraining's auc: 0.951149\tvalid_1's auc: 0.915099\n",
      "Fold_2\n",
      "1000\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.799828\tvalid_1's auc: 0.796333\n",
      "[1000]\ttraining's auc: 0.833936\tvalid_1's auc: 0.829519\n",
      "[1500]\ttraining's auc: 0.853787\tvalid_1's auc: 0.848514\n",
      "[2000]\ttraining's auc: 0.866578\tvalid_1's auc: 0.860722\n",
      "[2500]\ttraining's auc: 0.875608\tvalid_1's auc: 0.86927\n",
      "[3000]\ttraining's auc: 0.882776\tvalid_1's auc: 0.876182\n",
      "[3500]\ttraining's auc: 0.888434\tvalid_1's auc: 0.881591\n",
      "[4000]\ttraining's auc: 0.893084\tvalid_1's auc: 0.885889\n",
      "[4500]\ttraining's auc: 0.897023\tvalid_1's auc: 0.889787\n",
      "[5000]\ttraining's auc: 0.900603\tvalid_1's auc: 0.893044\n",
      "[5500]\ttraining's auc: 0.90337\tvalid_1's auc: 0.895665\n",
      "[6000]\ttraining's auc: 0.905848\tvalid_1's auc: 0.897921\n",
      "[6500]\ttraining's auc: 0.908149\tvalid_1's auc: 0.900048\n",
      "[7000]\ttraining's auc: 0.910128\tvalid_1's auc: 0.901748\n",
      "[7500]\ttraining's auc: 0.912012\tvalid_1's auc: 0.90338\n",
      "[8000]\ttraining's auc: 0.913638\tvalid_1's auc: 0.904794\n",
      "[8500]\ttraining's auc: 0.915229\tvalid_1's auc: 0.906061\n",
      "[9000]\ttraining's auc: 0.916641\tvalid_1's auc: 0.907176\n",
      "[9500]\ttraining's auc: 0.917967\tvalid_1's auc: 0.908374\n",
      "[10000]\ttraining's auc: 0.919175\tvalid_1's auc: 0.909403\n",
      "[10500]\ttraining's auc: 0.920335\tvalid_1's auc: 0.910306\n",
      "[11000]\ttraining's auc: 0.921335\tvalid_1's auc: 0.911092\n",
      "[11500]\ttraining's auc: 0.922354\tvalid_1's auc: 0.911838\n",
      "[12000]\ttraining's auc: 0.92328\tvalid_1's auc: 0.91248\n",
      "[12500]\ttraining's auc: 0.924153\tvalid_1's auc: 0.913128\n",
      "[13000]\ttraining's auc: 0.924961\tvalid_1's auc: 0.913676\n",
      "[13500]\ttraining's auc: 0.925752\tvalid_1's auc: 0.914202\n",
      "[14000]\ttraining's auc: 0.926471\tvalid_1's auc: 0.914724\n",
      "[14500]\ttraining's auc: 0.927203\tvalid_1's auc: 0.915223\n",
      "[15000]\ttraining's auc: 0.927849\tvalid_1's auc: 0.915655\n",
      "[15500]\ttraining's auc: 0.928515\tvalid_1's auc: 0.916133\n",
      "[16000]\ttraining's auc: 0.929192\tvalid_1's auc: 0.916549\n",
      "[16500]\ttraining's auc: 0.9298\tvalid_1's auc: 0.916891\n",
      "[17000]\ttraining's auc: 0.930384\tvalid_1's auc: 0.91725\n",
      "[17500]\ttraining's auc: 0.930978\tvalid_1's auc: 0.917519\n",
      "[18000]\ttraining's auc: 0.931538\tvalid_1's auc: 0.917797\n",
      "[18500]\ttraining's auc: 0.93209\tvalid_1's auc: 0.917995\n",
      "[19000]\ttraining's auc: 0.932636\tvalid_1's auc: 0.918218\n",
      "[19500]\ttraining's auc: 0.933154\tvalid_1's auc: 0.918448\n",
      "[20000]\ttraining's auc: 0.9337\tvalid_1's auc: 0.918687\n",
      "[20500]\ttraining's auc: 0.934235\tvalid_1's auc: 0.918889\n",
      "[21000]\ttraining's auc: 0.934768\tvalid_1's auc: 0.919103\n",
      "[21500]\ttraining's auc: 0.935267\tvalid_1's auc: 0.919278\n",
      "[22000]\ttraining's auc: 0.935772\tvalid_1's auc: 0.919496\n",
      "[22500]\ttraining's auc: 0.936271\tvalid_1's auc: 0.919685\n",
      "[23000]\ttraining's auc: 0.93677\tvalid_1's auc: 0.919831\n",
      "[23500]\ttraining's auc: 0.93724\tvalid_1's auc: 0.919961\n",
      "[24000]\ttraining's auc: 0.93772\tvalid_1's auc: 0.920087\n",
      "[24500]\ttraining's auc: 0.938177\tvalid_1's auc: 0.920222\n",
      "[25000]\ttraining's auc: 0.938641\tvalid_1's auc: 0.920325\n",
      "[25500]\ttraining's auc: 0.939089\tvalid_1's auc: 0.920439\n",
      "[26000]\ttraining's auc: 0.939519\tvalid_1's auc: 0.92055\n",
      "[26500]\ttraining's auc: 0.939991\tvalid_1's auc: 0.920711\n",
      "[27000]\ttraining's auc: 0.94043\tvalid_1's auc: 0.9208\n",
      "[27500]\ttraining's auc: 0.940882\tvalid_1's auc: 0.920846\n",
      "[28000]\ttraining's auc: 0.941312\tvalid_1's auc: 0.920903\n",
      "[28500]\ttraining's auc: 0.941761\tvalid_1's auc: 0.921\n",
      "[29000]\ttraining's auc: 0.942164\tvalid_1's auc: 0.921085\n",
      "[29500]\ttraining's auc: 0.942595\tvalid_1's auc: 0.921182\n",
      "[30000]\ttraining's auc: 0.943021\tvalid_1's auc: 0.921232\n",
      "[30500]\ttraining's auc: 0.943402\tvalid_1's auc: 0.921279\n",
      "[31000]\ttraining's auc: 0.943805\tvalid_1's auc: 0.921368\n",
      "[31500]\ttraining's auc: 0.944203\tvalid_1's auc: 0.921417\n",
      "[32000]\ttraining's auc: 0.944595\tvalid_1's auc: 0.921477\n",
      "[32500]\ttraining's auc: 0.944992\tvalid_1's auc: 0.921548\n",
      "[33000]\ttraining's auc: 0.945391\tvalid_1's auc: 0.92156\n",
      "[33500]\ttraining's auc: 0.945771\tvalid_1's auc: 0.921596\n",
      "[34000]\ttraining's auc: 0.946163\tvalid_1's auc: 0.92162\n",
      "[34500]\ttraining's auc: 0.946537\tvalid_1's auc: 0.921681\n",
      "[35000]\ttraining's auc: 0.946906\tvalid_1's auc: 0.921753\n",
      "[35500]\ttraining's auc: 0.947294\tvalid_1's auc: 0.921821\n",
      "[36000]\ttraining's auc: 0.947668\tvalid_1's auc: 0.921875\n",
      "[36500]\ttraining's auc: 0.948055\tvalid_1's auc: 0.921925\n",
      "[37000]\ttraining's auc: 0.948419\tvalid_1's auc: 0.921927\n",
      "[37500]\ttraining's auc: 0.948781\tvalid_1's auc: 0.921956\n",
      "[38000]\ttraining's auc: 0.949135\tvalid_1's auc: 0.921986\n",
      "[38500]\ttraining's auc: 0.949489\tvalid_1's auc: 0.921991\n",
      "[39000]\ttraining's auc: 0.949866\tvalid_1's auc: 0.921977\n",
      "[39500]\ttraining's auc: 0.950209\tvalid_1's auc: 0.922026\n",
      "[40000]\ttraining's auc: 0.95056\tvalid_1's auc: 0.922081\n",
      "[40500]\ttraining's auc: 0.950908\tvalid_1's auc: 0.922129\n",
      "[41000]\ttraining's auc: 0.95126\tvalid_1's auc: 0.922178\n",
      "[41500]\ttraining's auc: 0.951601\tvalid_1's auc: 0.922212\n",
      "[42000]\ttraining's auc: 0.951943\tvalid_1's auc: 0.922227\n",
      "[42500]\ttraining's auc: 0.952292\tvalid_1's auc: 0.922253\n",
      "[43000]\ttraining's auc: 0.952606\tvalid_1's auc: 0.922278\n",
      "[43500]\ttraining's auc: 0.952939\tvalid_1's auc: 0.922282\n",
      "[44000]\ttraining's auc: 0.953275\tvalid_1's auc: 0.922323\n",
      "[44500]\ttraining's auc: 0.953604\tvalid_1's auc: 0.922377\n",
      "[45000]\ttraining's auc: 0.953916\tvalid_1's auc: 0.92242\n",
      "[45500]\ttraining's auc: 0.95423\tvalid_1's auc: 0.922427\n",
      "[46000]\ttraining's auc: 0.954539\tvalid_1's auc: 0.922428\n",
      "[46500]\ttraining's auc: 0.954863\tvalid_1's auc: 0.92244\n",
      "[47000]\ttraining's auc: 0.955188\tvalid_1's auc: 0.92244\n",
      "Early stopping, best iteration is:\n",
      "[46328]\ttraining's auc: 0.954747\tvalid_1's auc: 0.922464\n",
      "Fold_3\n",
      "1000\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.800872\tvalid_1's auc: 0.785597\n",
      "[1000]\ttraining's auc: 0.835587\tvalid_1's auc: 0.820947\n",
      "[1500]\ttraining's auc: 0.854188\tvalid_1's auc: 0.839505\n",
      "[2000]\ttraining's auc: 0.866942\tvalid_1's auc: 0.852201\n",
      "[2500]\ttraining's auc: 0.876428\tvalid_1's auc: 0.861068\n",
      "[3000]\ttraining's auc: 0.883609\tvalid_1's auc: 0.868086\n",
      "[3500]\ttraining's auc: 0.889458\tvalid_1's auc: 0.873728\n",
      "[4000]\ttraining's auc: 0.894305\tvalid_1's auc: 0.878221\n",
      "[4500]\ttraining's auc: 0.898237\tvalid_1's auc: 0.881876\n",
      "[5000]\ttraining's auc: 0.901745\tvalid_1's auc: 0.885099\n",
      "[5500]\ttraining's auc: 0.904866\tvalid_1's auc: 0.887881\n",
      "[6000]\ttraining's auc: 0.9074\tvalid_1's auc: 0.890068\n",
      "[6500]\ttraining's auc: 0.909638\tvalid_1's auc: 0.892162\n",
      "[7000]\ttraining's auc: 0.911702\tvalid_1's auc: 0.893987\n",
      "[7500]\ttraining's auc: 0.913558\tvalid_1's auc: 0.895627\n",
      "[8000]\ttraining's auc: 0.915176\tvalid_1's auc: 0.897006\n",
      "[8500]\ttraining's auc: 0.91678\tvalid_1's auc: 0.898413\n",
      "[9000]\ttraining's auc: 0.918154\tvalid_1's auc: 0.899538\n",
      "[9500]\ttraining's auc: 0.919426\tvalid_1's auc: 0.900548\n",
      "[10000]\ttraining's auc: 0.920627\tvalid_1's auc: 0.90166\n",
      "[10500]\ttraining's auc: 0.921732\tvalid_1's auc: 0.902496\n",
      "[11000]\ttraining's auc: 0.922786\tvalid_1's auc: 0.903364\n",
      "[11500]\ttraining's auc: 0.923808\tvalid_1's auc: 0.90419\n",
      "[12000]\ttraining's auc: 0.924684\tvalid_1's auc: 0.904916\n",
      "[12500]\ttraining's auc: 0.925521\tvalid_1's auc: 0.905635\n",
      "[13000]\ttraining's auc: 0.926289\tvalid_1's auc: 0.906198\n",
      "[13500]\ttraining's auc: 0.927069\tvalid_1's auc: 0.9068\n",
      "[14000]\ttraining's auc: 0.927774\tvalid_1's auc: 0.907328\n",
      "[14500]\ttraining's auc: 0.928523\tvalid_1's auc: 0.907882\n",
      "[15000]\ttraining's auc: 0.929172\tvalid_1's auc: 0.908278\n",
      "[15500]\ttraining's auc: 0.929847\tvalid_1's auc: 0.908742\n",
      "[16000]\ttraining's auc: 0.930452\tvalid_1's auc: 0.909171\n",
      "[16500]\ttraining's auc: 0.931074\tvalid_1's auc: 0.909509\n",
      "[17000]\ttraining's auc: 0.931638\tvalid_1's auc: 0.909899\n",
      "[17500]\ttraining's auc: 0.932238\tvalid_1's auc: 0.910223\n",
      "[18000]\ttraining's auc: 0.932779\tvalid_1's auc: 0.910522\n",
      "[18500]\ttraining's auc: 0.93335\tvalid_1's auc: 0.910817\n",
      "[19000]\ttraining's auc: 0.933877\tvalid_1's auc: 0.911082\n",
      "[19500]\ttraining's auc: 0.934382\tvalid_1's auc: 0.911332\n",
      "[20000]\ttraining's auc: 0.934897\tvalid_1's auc: 0.911682\n",
      "[20500]\ttraining's auc: 0.935374\tvalid_1's auc: 0.911869\n",
      "[21000]\ttraining's auc: 0.935902\tvalid_1's auc: 0.91211\n",
      "[21500]\ttraining's auc: 0.936401\tvalid_1's auc: 0.912348\n",
      "[22000]\ttraining's auc: 0.936881\tvalid_1's auc: 0.912523\n",
      "[22500]\ttraining's auc: 0.93741\tvalid_1's auc: 0.912741\n",
      "[23000]\ttraining's auc: 0.937894\tvalid_1's auc: 0.912911\n",
      "[23500]\ttraining's auc: 0.93838\tvalid_1's auc: 0.913076\n",
      "[24000]\ttraining's auc: 0.938838\tvalid_1's auc: 0.913208\n",
      "[24500]\ttraining's auc: 0.939311\tvalid_1's auc: 0.913443\n",
      "[25000]\ttraining's auc: 0.939758\tvalid_1's auc: 0.913513\n",
      "[25500]\ttraining's auc: 0.940228\tvalid_1's auc: 0.913715\n",
      "[26000]\ttraining's auc: 0.940671\tvalid_1's auc: 0.913872\n",
      "[26500]\ttraining's auc: 0.941104\tvalid_1's auc: 0.913997\n",
      "[27000]\ttraining's auc: 0.941538\tvalid_1's auc: 0.914135\n",
      "[27500]\ttraining's auc: 0.941969\tvalid_1's auc: 0.914248\n",
      "[28000]\ttraining's auc: 0.942422\tvalid_1's auc: 0.914377\n",
      "[28500]\ttraining's auc: 0.942843\tvalid_1's auc: 0.914523\n",
      "[29000]\ttraining's auc: 0.943264\tvalid_1's auc: 0.914606\n",
      "[29500]\ttraining's auc: 0.943681\tvalid_1's auc: 0.914748\n",
      "[30000]\ttraining's auc: 0.944096\tvalid_1's auc: 0.914808\n",
      "[30500]\ttraining's auc: 0.944503\tvalid_1's auc: 0.914906\n",
      "[31000]\ttraining's auc: 0.944913\tvalid_1's auc: 0.915009\n",
      "[31500]\ttraining's auc: 0.945331\tvalid_1's auc: 0.915085\n",
      "[32000]\ttraining's auc: 0.945729\tvalid_1's auc: 0.915144\n",
      "[32500]\ttraining's auc: 0.946123\tvalid_1's auc: 0.915206\n",
      "[33000]\ttraining's auc: 0.946519\tvalid_1's auc: 0.915265\n",
      "[33500]\ttraining's auc: 0.946898\tvalid_1's auc: 0.915337\n",
      "[34000]\ttraining's auc: 0.947265\tvalid_1's auc: 0.915391\n",
      "[34500]\ttraining's auc: 0.947664\tvalid_1's auc: 0.915436\n",
      "[35000]\ttraining's auc: 0.948041\tvalid_1's auc: 0.915517\n",
      "[35500]\ttraining's auc: 0.948397\tvalid_1's auc: 0.915577\n",
      "[36000]\ttraining's auc: 0.948749\tvalid_1's auc: 0.915585\n",
      "[36500]\ttraining's auc: 0.949106\tvalid_1's auc: 0.915661\n",
      "[37000]\ttraining's auc: 0.949462\tvalid_1's auc: 0.915669\n",
      "[37500]\ttraining's auc: 0.94981\tvalid_1's auc: 0.915685\n",
      "[38000]\ttraining's auc: 0.950166\tvalid_1's auc: 0.9157\n",
      "[38500]\ttraining's auc: 0.950517\tvalid_1's auc: 0.915765\n",
      "[39000]\ttraining's auc: 0.950874\tvalid_1's auc: 0.915818\n",
      "[39500]\ttraining's auc: 0.951229\tvalid_1's auc: 0.915898\n",
      "[40000]\ttraining's auc: 0.951571\tvalid_1's auc: 0.915944\n",
      "[40500]\ttraining's auc: 0.951923\tvalid_1's auc: 0.916024\n",
      "[41000]\ttraining's auc: 0.95224\tvalid_1's auc: 0.916069\n",
      "[41500]\ttraining's auc: 0.952563\tvalid_1's auc: 0.916093\n",
      "[42000]\ttraining's auc: 0.952912\tvalid_1's auc: 0.916148\n",
      "[42500]\ttraining's auc: 0.953251\tvalid_1's auc: 0.916179\n",
      "[43000]\ttraining's auc: 0.953565\tvalid_1's auc: 0.916175\n",
      "[43500]\ttraining's auc: 0.95389\tvalid_1's auc: 0.916209\n",
      "[44000]\ttraining's auc: 0.95421\tvalid_1's auc: 0.916251\n",
      "[44500]\ttraining's auc: 0.954537\tvalid_1's auc: 0.916283\n",
      "[45000]\ttraining's auc: 0.95486\tvalid_1's auc: 0.916253\n",
      "Early stopping, best iteration is:\n",
      "[44473]\ttraining's auc: 0.954521\tvalid_1's auc: 0.916289\n",
      "Fold_4\n",
      "1000\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.802502\tvalid_1's auc: 0.797338\n",
      "[1000]\ttraining's auc: 0.83671\tvalid_1's auc: 0.827114\n",
      "[1500]\ttraining's auc: 0.856183\tvalid_1's auc: 0.844488\n",
      "[2000]\ttraining's auc: 0.868824\tvalid_1's auc: 0.855984\n",
      "[2500]\ttraining's auc: 0.877983\tvalid_1's auc: 0.863971\n",
      "[3000]\ttraining's auc: 0.885042\tvalid_1's auc: 0.870099\n",
      "[3500]\ttraining's auc: 0.890771\tvalid_1's auc: 0.875176\n",
      "[4000]\ttraining's auc: 0.895289\tvalid_1's auc: 0.879303\n",
      "[4500]\ttraining's auc: 0.898991\tvalid_1's auc: 0.882507\n",
      "[5000]\ttraining's auc: 0.902159\tvalid_1's auc: 0.885506\n",
      "[5500]\ttraining's auc: 0.904957\tvalid_1's auc: 0.887894\n",
      "[6000]\ttraining's auc: 0.907439\tvalid_1's auc: 0.890142\n",
      "[6500]\ttraining's auc: 0.909756\tvalid_1's auc: 0.892092\n",
      "[7000]\ttraining's auc: 0.911791\tvalid_1's auc: 0.893921\n",
      "[7500]\ttraining's auc: 0.913615\tvalid_1's auc: 0.895545\n",
      "[8000]\ttraining's auc: 0.915297\tvalid_1's auc: 0.897052\n",
      "[8500]\ttraining's auc: 0.916858\tvalid_1's auc: 0.898296\n",
      "[9000]\ttraining's auc: 0.918315\tvalid_1's auc: 0.899564\n",
      "[9500]\ttraining's auc: 0.919583\tvalid_1's auc: 0.900593\n",
      "[10000]\ttraining's auc: 0.920799\tvalid_1's auc: 0.90159\n",
      "[10500]\ttraining's auc: 0.921868\tvalid_1's auc: 0.902551\n",
      "[11000]\ttraining's auc: 0.922862\tvalid_1's auc: 0.903332\n",
      "[11500]\ttraining's auc: 0.923837\tvalid_1's auc: 0.904106\n",
      "[12000]\ttraining's auc: 0.924793\tvalid_1's auc: 0.904865\n",
      "[12500]\ttraining's auc: 0.925666\tvalid_1's auc: 0.905513\n",
      "[13000]\ttraining's auc: 0.926481\tvalid_1's auc: 0.906178\n",
      "[13500]\ttraining's auc: 0.927252\tvalid_1's auc: 0.906781\n",
      "[14000]\ttraining's auc: 0.92803\tvalid_1's auc: 0.907428\n",
      "[14500]\ttraining's auc: 0.928742\tvalid_1's auc: 0.907897\n",
      "[15000]\ttraining's auc: 0.929418\tvalid_1's auc: 0.908346\n",
      "[15500]\ttraining's auc: 0.930042\tvalid_1's auc: 0.908694\n",
      "[16000]\ttraining's auc: 0.93065\tvalid_1's auc: 0.90913\n",
      "[16500]\ttraining's auc: 0.931244\tvalid_1's auc: 0.909468\n",
      "[17000]\ttraining's auc: 0.931851\tvalid_1's auc: 0.909855\n",
      "[17500]\ttraining's auc: 0.932416\tvalid_1's auc: 0.910182\n",
      "[18000]\ttraining's auc: 0.932956\tvalid_1's auc: 0.910514\n",
      "[18500]\ttraining's auc: 0.933502\tvalid_1's auc: 0.910755\n",
      "[19000]\ttraining's auc: 0.934034\tvalid_1's auc: 0.911059\n",
      "[19500]\ttraining's auc: 0.934558\tvalid_1's auc: 0.911307\n",
      "[20000]\ttraining's auc: 0.935095\tvalid_1's auc: 0.911564\n",
      "[20500]\ttraining's auc: 0.935621\tvalid_1's auc: 0.9118\n",
      "[21000]\ttraining's auc: 0.936168\tvalid_1's auc: 0.912005\n",
      "[21500]\ttraining's auc: 0.936669\tvalid_1's auc: 0.912193\n",
      "[22000]\ttraining's auc: 0.937184\tvalid_1's auc: 0.912399\n",
      "[22500]\ttraining's auc: 0.937656\tvalid_1's auc: 0.912585\n",
      "[23000]\ttraining's auc: 0.938129\tvalid_1's auc: 0.91276\n",
      "[23500]\ttraining's auc: 0.938572\tvalid_1's auc: 0.912908\n",
      "[24000]\ttraining's auc: 0.939052\tvalid_1's auc: 0.913104\n",
      "[24500]\ttraining's auc: 0.939502\tvalid_1's auc: 0.913243\n",
      "[25000]\ttraining's auc: 0.939951\tvalid_1's auc: 0.913326\n",
      "[25500]\ttraining's auc: 0.940415\tvalid_1's auc: 0.913451\n",
      "[26000]\ttraining's auc: 0.940879\tvalid_1's auc: 0.913577\n",
      "[26500]\ttraining's auc: 0.941318\tvalid_1's auc: 0.913673\n",
      "[27000]\ttraining's auc: 0.941754\tvalid_1's auc: 0.913802\n",
      "[27500]\ttraining's auc: 0.942195\tvalid_1's auc: 0.913885\n",
      "[28000]\ttraining's auc: 0.942614\tvalid_1's auc: 0.913977\n",
      "[28500]\ttraining's auc: 0.943042\tvalid_1's auc: 0.91404\n",
      "[29000]\ttraining's auc: 0.943437\tvalid_1's auc: 0.914136\n",
      "[29500]\ttraining's auc: 0.94385\tvalid_1's auc: 0.914246\n",
      "[30000]\ttraining's auc: 0.944249\tvalid_1's auc: 0.914319\n",
      "[30500]\ttraining's auc: 0.944659\tvalid_1's auc: 0.914357\n",
      "[31000]\ttraining's auc: 0.94507\tvalid_1's auc: 0.914438\n",
      "[31500]\ttraining's auc: 0.945465\tvalid_1's auc: 0.914506\n",
      "[32000]\ttraining's auc: 0.945861\tvalid_1's auc: 0.914584\n",
      "[32500]\ttraining's auc: 0.946257\tvalid_1's auc: 0.914664\n",
      "[33000]\ttraining's auc: 0.946655\tvalid_1's auc: 0.914716\n",
      "[33500]\ttraining's auc: 0.947054\tvalid_1's auc: 0.914828\n",
      "[34000]\ttraining's auc: 0.947437\tvalid_1's auc: 0.91486\n",
      "[34500]\ttraining's auc: 0.947795\tvalid_1's auc: 0.914886\n",
      "[35000]\ttraining's auc: 0.948175\tvalid_1's auc: 0.914889\n",
      "[35500]\ttraining's auc: 0.948527\tvalid_1's auc: 0.914974\n",
      "[36000]\ttraining's auc: 0.9489\tvalid_1's auc: 0.915021\n",
      "[36500]\ttraining's auc: 0.949264\tvalid_1's auc: 0.915084\n",
      "[37000]\ttraining's auc: 0.949633\tvalid_1's auc: 0.915156\n",
      "[37500]\ttraining's auc: 0.950007\tvalid_1's auc: 0.915216\n",
      "[38000]\ttraining's auc: 0.950359\tvalid_1's auc: 0.915254\n",
      "[38500]\ttraining's auc: 0.950727\tvalid_1's auc: 0.91528\n",
      "[39000]\ttraining's auc: 0.951073\tvalid_1's auc: 0.915314\n",
      "[39500]\ttraining's auc: 0.95142\tvalid_1's auc: 0.915329\n",
      "[40000]\ttraining's auc: 0.951777\tvalid_1's auc: 0.915392\n",
      "[40500]\ttraining's auc: 0.952113\tvalid_1's auc: 0.915414\n",
      "[41000]\ttraining's auc: 0.952462\tvalid_1's auc: 0.915415\n",
      "[41500]\ttraining's auc: 0.952797\tvalid_1's auc: 0.915436\n",
      "[42000]\ttraining's auc: 0.953145\tvalid_1's auc: 0.915458\n",
      "[42500]\ttraining's auc: 0.95346\tvalid_1's auc: 0.91548\n",
      "[43000]\ttraining's auc: 0.953805\tvalid_1's auc: 0.915495\n",
      "[43500]\ttraining's auc: 0.954146\tvalid_1's auc: 0.915511\n",
      "[44000]\ttraining's auc: 0.954482\tvalid_1's auc: 0.915528\n",
      "[44500]\ttraining's auc: 0.95481\tvalid_1's auc: 0.915528\n",
      "[45000]\ttraining's auc: 0.955139\tvalid_1's auc: 0.915559\n",
      "[45500]\ttraining's auc: 0.955471\tvalid_1's auc: 0.915588\n",
      "[46000]\ttraining's auc: 0.955798\tvalid_1's auc: 0.915568\n",
      "[46500]\ttraining's auc: 0.9561\tvalid_1's auc: 0.915614\n",
      "[47000]\ttraining's auc: 0.956417\tvalid_1's auc: 0.91563\n",
      "[47500]\ttraining's auc: 0.956728\tvalid_1's auc: 0.915669\n",
      "[48000]\ttraining's auc: 0.957025\tvalid_1's auc: 0.915686\n",
      "[48500]\ttraining's auc: 0.957325\tvalid_1's auc: 0.915687\n",
      "[49000]\ttraining's auc: 0.957644\tvalid_1's auc: 0.915662\n",
      "Early stopping, best iteration is:\n",
      "[48429]\ttraining's auc: 0.957287\tvalid_1's auc: 0.915698\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, x_train[\"target\"])):\n",
    "    fold_num = f\"Fold_{fold_}\"\n",
    "    print(fold_num)\n",
    "    build = x_train.loc[trn_idx, :]\n",
    "    val = x_train.loc[val_idx, :]\n",
    "    cols_for_model = raw_columns + engineered_columns\n",
    "    print(len(cols_for_model))\n",
    "    lbuild = lgb.Dataset(build[cols_for_model], label=build['target'])\n",
    "    lval = lgb.Dataset(val[cols_for_model], label=val['target'], reference=lbuild)\n",
    "    clf = lgb.train(params, lbuild, num_rounds, valid_sets=[lbuild, lval], verbose_eval=500, early_stopping_rounds=1000)\n",
    "    model_objects[fold_num] = clf\n",
    "    val_preds = clf.predict(val[cols_for_model], num_iteration=clf.best_iteration)\n",
    "    oof[val_idx] = val_preds\n",
    "    predictions += clf.predict(x_test_final[cols_for_model], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174341029325582"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([m.best_score[\"valid_1\"][\"auc\"] for m in model_objects.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({\"ID_code\": x_test_final[\"ID_code\"], \"target\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.175899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_7</td>\n",
       "      <td>0.083944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_11</td>\n",
       "      <td>0.032120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_15</td>\n",
       "      <td>0.012510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_16</td>\n",
       "      <td>0.461827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code    target\n",
       "0   test_3  0.175899\n",
       "1   test_7  0.083944\n",
       "2  test_11  0.032120\n",
       "3  test_15  0.012510\n",
       "4  test_16  0.461827"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"../submissions/version_1000featuresNew_cv91744.csv.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
